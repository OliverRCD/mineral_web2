# models/predictor.py
import torch
import torch.nn as nn
from torchvision import models
from PIL import Image
from torchvision import transforms
import json
import os


class MineralPredictor:
    def __init__(self, model_path, class_mapping_path, full_mapping_path, device=None):
        """
        model_path: è®­ç»ƒä¿å­˜çš„æ¨¡å‹æ–‡ä»¶ (.pth)
        class_mapping_path: è®­ç»ƒå­é›† class_mapping.jsonï¼ˆè‹±æ–‡åç§°åˆ—è¡¨ï¼‰
        full_mapping_path: å®Œæ•´ä¸­è‹±æ–‡æ˜ å°„è¡¨ full_class_mapping.json
        """
        self.device = device or "cpu"
        print(f"ğŸ¯ åŠ è½½æ¨¡å‹åˆ°è®¾å¤‡: {self.device}")

        model_name = os.path.splitext(os.path.basename(model_path))[0]
        os.makedirs("data", exist_ok=True)
        subset_mapping_path = os.path.join("data", f"{model_name}_classes.json")

        # 1ï¸âƒ£ åŠ è½½è®­ç»ƒå­é›†è‹±æ–‡åˆ—è¡¨
        with open(class_mapping_path, 'r', encoding='utf-8') as f:
            train_classes = json.load(f)  # {"0": "actinolite", ...}
        print(f"ğŸ“š å·²åŠ è½½è®­ç»ƒå­é›†è‹±æ–‡ç±»åˆ«ï¼Œå…± {len(train_classes)} ä¸ª")

        # 2ï¸âƒ£ åŠ è½½å®Œæ•´ä¸­è‹±æ–‡æ˜ å°„è¡¨
        with open(full_mapping_path, 'r', encoding='utf-8') as f:
            full_mapping = json.load(f)  # {"0": {"en":"actinolite","zh":"é˜³èµ·çŸ³"}, ...}

        # 3ï¸âƒ£ åŠ è½½ checkpoint
        print(f"ğŸ”§ åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹: {model_path}")
        checkpoint = torch.load(model_path, map_location=self.device)

        # 4ï¸âƒ£ è·å–æƒé‡ç»“æ„
        if 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
            print("âœ… æ£€æµ‹åˆ°åµŒå¥—æ ¼å¼ï¼ˆmodel_state_dictï¼‰")
        else:
            state_dict = checkpoint
            print("âœ… æ£€æµ‹åˆ°çº¯ state_dict æ ¼å¼")

        # è‡ªåŠ¨æ¨æ–­ç±»åˆ«æ•°
        if 'fc.weight' in state_dict:
            num_classes_model = state_dict['fc.weight'].shape[0]
            in_features = state_dict['fc.weight'].shape[1]
            print(f"âœ… æ¨¡å‹è¾“å‡ºç±»åˆ«: {num_classes_model}ï¼Œfc è¾“å…¥ç»´åº¦: {in_features}")
        else:
            raise RuntimeError("âŒ æ¨¡å‹æƒé‡ä¸­æœªæ‰¾åˆ° fc.weight")

        # 5ï¸âƒ£ æ„å»ºéª¨å¹²ç½‘ç»œ
        if in_features == 512:
            self.model = models.resnet18(weights=None)
            self.model.fc = nn.Linear(512, num_classes_model)
        elif in_features == 2048:
            self.model = models.resnet50(weights=None)
            self.model.fc = nn.Linear(2048, num_classes_model)
        else:
            print(f"âš ï¸ æœªçŸ¥çš„ fc è¾“å…¥ç»´åº¦ {in_features}ï¼Œä½¿ç”¨ ResNet18 å…¼å®¹åŠ è½½")
            self.model = models.resnet18(weights=None)
            self.model.fc = nn.Linear(512, num_classes_model)

        self.model.to(self.device)

        # 6ï¸âƒ£ åŠ è½½æƒé‡
        missing, unexpected = self.model.load_state_dict(state_dict, strict=False)
        if missing:
            print(f"âš ï¸ æœ‰ç¼ºå¤±çš„å±‚æœªåŠ è½½: {len(missing)} ä¸ª")
        if unexpected:
            print(f"âš ï¸ æœ‰å¤šä½™çš„å±‚æœªåŒ¹é…: {len(unexpected)} ä¸ª")
        print("âœ… æ¨¡å‹æƒé‡åŠ è½½å®Œæˆï¼ˆå·²å¿½ç•¥ä¸åŒ¹é…å±‚ï¼‰")

        # åœ¨åŠ è½½æƒé‡åæ·»åŠ 
        print("ğŸ” æ£€æŸ¥æ¨¡å‹æƒé‡...")
        for name, param in self.model.named_parameters():
            if 'fc' in name:
                print(f"ğŸ” {name}: {param.data.abs().mean().item():.6f}")
                break

        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åœ¨è®­ç»ƒæ¨¡å¼
        print(f"ğŸ” æ¨¡å‹æ¨¡å¼: {'è®­ç»ƒ' if self.model.training else 'è¯„ä¼°'}")
        # 7ï¸âƒ£ ä¿®æ­£åç§°æ˜ å°„é€»è¾‘
        # æ„å»ºå®Œæ•´æ˜ å°„çš„è‹±æ–‡åˆ°ä¸­æ–‡å­—å…¸ï¼ˆä½¿ç”¨åŸå§‹è‹±æ–‡åç§°ï¼‰
        en_to_zh = {}
        for item in full_mapping.values():
            en_name = item['en'].strip()
            zh_name = item['zh'].strip()
            en_to_zh[en_name] = zh_name

        print(f"ğŸ“– å®Œæ•´æ˜ å°„è¡¨åŒ…å« {len(en_to_zh)} ä¸ªç±»åˆ«")

        # æ„å»ºè®­ç»ƒç´¢å¼• -> è‹±æ–‡ + ä¸­æ–‡
        self.idx_to_class = {}
        sorted_keys = sorted(train_classes.keys(), key=int)

        found_count = 0
        not_found_classes = []

        for idx, key in enumerate(sorted_keys):
            en_name = train_classes[key].strip()
            zh_name = en_to_zh.get(en_name)

            if zh_name:
                self.idx_to_class[idx] = {"en": en_name, "zh": zh_name}
                found_count += 1
            else:
                # å¦‚æœç›´æ¥åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…ï¼ˆå¿½ç•¥å¤§å°å†™å’Œç©ºæ ¼ï¼‰
                en_name_lower = en_name.lower().replace(' ', '')
                found = False

                for full_en, full_zh in en_to_zh.items():
                    full_en_lower = full_en.lower().replace(' ', '')
                    if en_name_lower == full_en_lower:
                        self.idx_to_class[idx] = {"en": en_name, "zh": full_zh}
                        found_count += 1
                        found = True
                        print(f"ğŸ”„ æ¨¡ç³ŠåŒ¹é…æˆåŠŸ: '{en_name}' -> '{full_en}'")
                        break

                if not found:
                    not_found_classes.append(en_name)
                    self.idx_to_class[idx] = {"en": en_name, "zh": "æœªçŸ¥"}
                    print(f"âš ï¸ æœªæ‰¾åˆ°æ˜ å°„: {en_name}")

        print(f"âœ… æˆåŠŸæ˜ å°„ {found_count}/{len(sorted_keys)} ä¸ªç±»åˆ«")
        if not_found_classes:
            print(f"âŒ æœªæ‰¾åˆ°æ˜ å°„çš„ç±»åˆ«: {not_found_classes}")

        # 8ï¸âƒ£ ä¿å­˜å­é›†æ˜ å°„ JSON
        with open(subset_mapping_path, 'w', encoding='utf-8') as f:
            json.dump(self.idx_to_class, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å·²ç”Ÿæˆæ¨¡å‹ç±»åˆ«æ–‡ä»¶: {subset_mapping_path}")

        # 9ï¸âƒ£ å›¾åƒé¢„å¤„ç†
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225]),
        ])

        # æ‰“å°å‰å‡ ä¸ªç±»åˆ«ä½œä¸ºéªŒè¯
        print("ğŸ” æ˜ å°„éªŒè¯ï¼ˆå‰5ä¸ªç±»åˆ«ï¼‰:")
        for i in range(min(5, len(self.idx_to_class))):
            info = self.idx_to_class[i]
            print(f"  {i}: {info['en']} -> {info['zh']}")

        # ğŸ”¥ åœ¨è¿™é‡Œæ·»åŠ æµ‹è¯•è°ƒç”¨ - åœ¨åˆå§‹åŒ–å®Œæˆåæµ‹è¯•æ¨¡å‹
        self.test_random_prediction()
    def predict(self, image_path, top_k=3):
        try:
            image = Image.open(image_path).convert('RGB')
            print(f"ğŸ“· æˆåŠŸåŠ è½½å›¾åƒ: {image_path}")
            print(f"ğŸ“ å›¾åƒå°ºå¯¸: {image.size}")
        except Exception as e:
            return {'error': f"æ— æ³•åŠ è½½å›¾åƒ: {str(e)}"}

        image = self.transform(image).unsqueeze(0).to(self.device)
        print(f"ğŸ”§ å›¾åƒé¢„å¤„ç†å®Œæˆï¼Œè¾“å…¥å¼ é‡å½¢çŠ¶: {image.shape}")

        with torch.no_grad():
            # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            self.model.eval()

            output = self.model(image)
            print(f"ğŸ“Š æ¨¡å‹åŸå§‹è¾“å‡ºå½¢çŠ¶: {output.shape}")
            print(f"ğŸ“Š æ¨¡å‹åŸå§‹è¾“å‡ºå€¼: {output}")

            probs = torch.softmax(output, dim=1)
            print(f"ğŸ“ˆ Softmaxåæ¦‚ç‡å½¢çŠ¶: {probs.shape}")
            print(f"ğŸ“ˆ æ¦‚ç‡å€¼: {probs}")

            top_probs, top_indices = torch.topk(probs, top_k)
            print(f"ğŸ† Top {top_k} ç´¢å¼•: {top_indices}")
            print(f"ğŸ† Top {top_k} æ¦‚ç‡: {top_probs}")

        results = []
        for i in range(top_k):
            idx = top_indices[0][i].item()
            prob = top_probs[0][i].item()
            label_info = self.idx_to_class.get(idx, {"en": "Unknown", "zh": "æœªçŸ¥"})
            results.append({
                'index': idx,
                'label_en': label_info['en'],
                'label_zh': label_info['zh'],
                'confidence': round(prob * 100, 2)
            })
            print(f"ğŸ” ç»“æœ {i + 1}: ç´¢å¼•={idx}, ç±»åˆ«={label_info}, ç½®ä¿¡åº¦={prob:.4f}")

        return results

    def test_random_prediction(self):
        """ç”Ÿæˆéšæœºè¾“å…¥æµ‹è¯•æ¨¡å‹è¾“å‡º"""
        print("ğŸ§ª è¿è¡Œéšæœºè¾“å…¥æµ‹è¯•...")
        random_input = torch.randn(1, 3, 224, 224).to(self.device)

        with torch.no_grad():
            self.model.eval()
            output = self.model(random_input)
            probs = torch.softmax(output, dim=1)
            max_prob, max_idx = torch.max(probs, 1)

            print(f"ğŸ§ª éšæœºè¾“å…¥æµ‹è¯• - æœ€å¤§æ¦‚ç‡ç´¢å¼•: {max_idx.item()}")
            print(f"ğŸ§ª éšæœºè¾“å…¥æµ‹è¯• - æœ€å¤§æ¦‚ç‡å€¼: {max_prob.item():.4f}")
            print(f"ğŸ§ª éšæœºè¾“å…¥æµ‹è¯• - æ‰€æœ‰æ¦‚ç‡åˆ†å¸ƒ: {probs[0][:10]}...")  # åªæ˜¾ç¤ºå‰10ä¸ª